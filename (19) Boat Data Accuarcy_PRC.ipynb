{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c53644",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4232109895.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\qlstl\\AppData\\Local\\Temp\\ipykernel_12516\\4232109895.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install requests\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n",
    "pip install beautifulsoup4\n",
    "pip install opencv-python\n",
    "pip install numpy\n",
    "pip install tensorflow\n",
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "def fetch_image_urls(query, max_links_to_fetch, headers):\n",
    "    search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    image_elements = soup.find_all('img', class_='rg_i')\n",
    "    \n",
    "    image_urls = []\n",
    "    for img in image_elements:\n",
    "        if img.has_attr('src'):\n",
    "            image_urls.append(img['src'])\n",
    "        if len(image_urls) >= max_links_to_fetch:\n",
    "            break\n",
    "    \n",
    "    return image_urls\n",
    "\n",
    "def download_images(image_urls, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            with open(os.path.join(save_dir, f'image_{i}.jpg'), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download image {i}: {e}\")\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "}\n",
    "\n",
    "boat_urls = fetch_image_urls('boat', max_links_to_fetch=50, headers=headers)\n",
    "yacht_urls = fetch_image_urls('yacht', max_links_to_fetch=50, headers=headers)\n",
    "\n",
    "download_images(boat_urls, 'boat_images')\n",
    "download_images(yacht_urls, 'yacht_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def extract_features(image_dir):\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    features = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = preprocess_image(image_path)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        feature = model.predict(image)\n",
    "        features.append(feature.flatten())\n",
    "    return features\n",
    "\n",
    "boat_features = extract_features('boat_images')\n",
    "yacht_features = extract_features('yacht_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 특징과 레이블 준비\n",
    "X = np.array(boat_features + yacht_features)\n",
    "y = np.array([0] * len(boat_features) + [1] * len(yacht_features))  # 0: Boat, 1: Yacht\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM 분류기 학습\n",
    "classifier = SVC(kernel='linear', probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 특정 이미지를 선별하여 저장\n",
    "def classify_and_save(image_dir, classifier, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = preprocess_image(image_path)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        feature = model.predict(image).flatten()\n",
    "        pred = classifier.predict([feature])[0]\n",
    "        \n",
    "        if pred == 1:  # Yacht로 분류된 이미지 저장\n",
    "            output_path = os.path.join(output_dir, image_name)\n",
    "            cv2.imwrite(output_path, cv2.imread(image_path))\n",
    "\n",
    "classify_and_save('boat_images', classifier, 'selected_images/boat')\n",
    "classify_and_save('yacht_images', classifier, 'selected_images/yacht')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기와 경로 설정\n",
    "IMG_SIZE = 128\n",
    "BOAT_DIR = 'boat_images'\n",
    "YACHT_DIR = 'yacht_images'\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process image {filename}: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# 보트와 요트 이미지 불러오기\n",
    "boat_images, boat_labels = load_images_from_folder(BOAT_DIR, 0)  # 0 for boat\n",
    "yacht_images, yacht_labels = load_images_from_folder(YACHT_DIR, 1)  # 1 for yacht\n",
    "\n",
    "# 이미지와 레이블 결합\n",
    "X = np.array(boat_images + yacht_images)\n",
    "y = np.array(boat_labels + yacht_labels)\n",
    "\n",
    "# 데이터 정규화 (0~1 사이 값으로 변환)\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# 데이터셋 분할 (80% 학습, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d703209e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12516\\586253412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 이미지 크기와 경로 설정\n",
    "IMG_SIZE = 128\n",
    "BOAT_DIR = 'boat_images'\n",
    "YACHT_DIR = 'yacht_images'\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process image {filename}: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# 보트와 요트 이미지 불러오기\n",
    "boat_images, boat_labels = load_images_from_folder(BOAT_DIR, 0)  # 0 for boat\n",
    "yacht_images, yacht_labels = load_images_from_folder(YACHT_DIR, 1)  # 1 for yacht\n",
    "\n",
    "# 이미지와 레이블 결합\n",
    "X = np.array(boat_images + yacht_images)\n",
    "y = np.array(boat_labels + yacht_labels)\n",
    "\n",
    "# 데이터 정규화 (0~1 사이 값으로 변환)\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# 데이터셋 분할 (80% 학습, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN 모델 정의\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # 이진 분류\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, validation_split=0.1, epochs=10, batch_size=32)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test loss: {test_loss:.2f}\")\n",
    "\n",
    "# 정확도 그래프\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 손실도 그래프\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b48e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fe715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe5375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd829d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79a8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f8ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd27f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cf5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
