{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0b2562",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4232109895.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\qlstl\\AppData\\Local\\Temp\\ipykernel_12516\\4232109895.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install requests\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install requests\n",
    "pip install beautifulsoup4\n",
    "pip install opencv-python\n",
    "pip install numpy\n",
    "pip install tensorflow\n",
    "pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86807c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "\n",
    "def fetch_image_urls(query, max_links_to_fetch, headers):\n",
    "    search_url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "    response = requests.get(search_url, headers=headers)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    image_elements = soup.find_all('img', class_='rg_i')\n",
    "    \n",
    "    image_urls = []\n",
    "    for img in image_elements:\n",
    "        if img.has_attr('src'):\n",
    "            image_urls.append(img['src'])\n",
    "        if len(image_urls) >= max_links_to_fetch:\n",
    "            break\n",
    "    \n",
    "    return image_urls\n",
    "\n",
    "def download_images(image_urls, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for i, url in enumerate(image_urls):\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            with open(os.path.join(save_dir, f'image_{i}.jpg'), 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download image {i}: {e}\")\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "}\n",
    "\n",
    "boat_urls = fetch_image_urls('boat', max_links_to_fetch=50, headers=headers)\n",
    "yacht_urls = fetch_image_urls('yacht', max_links_to_fetch=50, headers=headers)\n",
    "\n",
    "download_images(boat_urls, 'boat_images')\n",
    "download_images(yacht_urls, 'yacht_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def extract_features(image_dir):\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    features = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = preprocess_image(image_path)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        feature = model.predict(image)\n",
    "        features.append(feature.flatten())\n",
    "    return features\n",
    "\n",
    "boat_features = extract_features('boat_images')\n",
    "yacht_features = extract_features('yacht_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e6a889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 특징과 레이블 준비\n",
    "X = np.array(boat_features + yacht_features)\n",
    "y = np.array([0] * len(boat_features) + [1] * len(yacht_features))  # 0: Boat, 1: Yacht\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SVM 분류기 학습\n",
    "classifier = SVC(kernel='linear', probability=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# 특정 이미지를 선별하여 저장\n",
    "def classify_and_save(image_dir, classifier, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = preprocess_image(image_path)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        feature = model.predict(image).flatten()\n",
    "        pred = classifier.predict([feature])[0]\n",
    "        \n",
    "        if pred == 1:  # Yacht로 분류된 이미지 저장\n",
    "            output_path = os.path.join(output_dir, image_name)\n",
    "            cv2.imwrite(output_path, cv2.imread(image_path))\n",
    "\n",
    "classify_and_save('boat_images', classifier, 'selected_images/boat')\n",
    "classify_and_save('yacht_images', classifier, 'selected_images/yacht')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1bb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기와 경로 설정\n",
    "IMG_SIZE = 128\n",
    "BOAT_DIR = 'boat_images'\n",
    "YACHT_DIR = 'yacht_images'\n",
    "\n",
    "def load_images_from_folder(folder, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process image {filename}: {e}\")\n",
    "    return images, labels\n",
    "\n",
    "# 보트와 요트 이미지 불러오기\n",
    "boat_images, boat_labels = load_images_from_folder(BOAT_DIR, 0)  # 0 for boat\n",
    "yacht_images, yacht_labels = load_images_from_folder(YACHT_DIR, 1)  # 1 for yacht\n",
    "\n",
    "# 이미지와 레이블 결합\n",
    "X = np.array(boat_images + yacht_images)\n",
    "y = np.array(boat_labels + yacht_labels)\n",
    "\n",
    "# 데이터 정규화 (0~1 사이 값으로 변환)\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# 데이터셋 분할 (80% 학습, 20% 테스트)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc51d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ebe88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad8d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d58400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60e66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c3a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892edd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472a5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ccb2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
